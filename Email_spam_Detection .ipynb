{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fc2d5af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             name  \\\n",
      "0  0001.1999-12-10.farmer.ham.txt   \n",
      "1  0002.1999-12-13.farmer.ham.txt   \n",
      "2  0003.1999-12-14.farmer.ham.txt   \n",
      "3  0004.1999-12-14.farmer.ham.txt   \n",
      "4  0005.1999-12-14.farmer.ham.txt   \n",
      "\n",
      "                                             content category  \n",
      "0            Subject: christmas tree farm pictures\\n      ham  \n",
      "1  Subject: vastar resources , inc .\\ngary , prod...      ham  \n",
      "2  Subject: calpine daily gas nomination\\n- calpi...      ham  \n",
      "3  Subject: re : issue\\nfyi - see note below - al...      ham  \n",
      "4  Subject: meter 7268 nov allocation\\nfyi .\\n- -...      ham  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def read_spam():\n",
    "    category = 'spam'\n",
    "    directory = r\"D:\\project\\the forge\\enron1\\spam\"\n",
    "    return read_category(category, directory)\n",
    "\n",
    "def read_ham():\n",
    "    category = 'ham'\n",
    "    directory =r\"D:\\project\\the forge\\enron1\\ham\"\n",
    "    return read_category(category, directory)\n",
    "\n",
    "def read_category(category, directory):\n",
    "    emails = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if not filename.endswith(\".txt\"):\n",
    "            continue\n",
    "        with open(os.path.join(directory, filename), 'r', encoding='latin1') as fp:  # Added encoding to handle non-ASCII characters\n",
    "            try:\n",
    "                content = fp.read()\n",
    "                emails.append({'name': filename, 'content': content, 'category': category})\n",
    "            except Exception as e:\n",
    "                print(f'skipped {filename} due to {e}')\n",
    "    return emails\n",
    "\n",
    "ham = read_ham()\n",
    "spam = read_spam()\n",
    "\n",
    "df_ham = pd.DataFrame.from_records(ham)\n",
    "df_spam = pd.DataFrame.from_records(spam)\n",
    "\n",
    "df = pd.concat([df_ham, df_spam], ignore_index=True)\n",
    "\n",
    "# Optional: Display the DataFrame\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e42aa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello  world  this is a test \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocessor(e):\n",
    "    e = re.sub(r'[^a-zA-Z]', ' ', e)\n",
    "    e = e.lower()\n",
    "    return e\n",
    "text = \"Hello, World! This is a TEST.\"\n",
    "cleaned_text = preprocessor(text)\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9ecf867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1566    Subject: eastrans nomination change effective ...\n",
      "1988    Subject: re : personal information needs to be...\n",
      "1235    Subject: re : saudi arabia\\ni spoke to mr . ma...\n",
      "3276    Subject: hpl nom for may 24 , 2001\\n( see atta...\n",
      "3438    Subject: re : error repairs\\njay ,\\nfor june ,...\n",
      "                              ...                        \n",
      "1175    Subject: re : new production - sitara deals ne...\n",
      "2594    Subject: crosstex energy services - camden res...\n",
      "3377    Subject: lng mtg\\nwhen : wednesday , july 11 ,...\n",
      "5065    Subject: looking for ci _ . a . _ lis ? we ` r...\n",
      "2142    Subject: beaumont methanol\\nthis is to confirm...\n",
      "Name: content, Length: 1035, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "vectorizer = CountVectorizer(preprocessor=preprocessor)\n",
    "\n",
    "X = df['content'] \n",
    "y = df['category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54bfb081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (4137, 39999)\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"Training data shape: {X_train_vectorized.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "869eab91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9997582789460963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anudeep\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_reg_model = LogisticRegression()\n",
    "log_reg_model.fit(X_train_vectorized, y_train)\n",
    "train_accuracy = log_reg_model.score(X_train_vectorized, y_train)\n",
    "print(f\"Training accuracy: {train_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f570de53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['ham' 'ham' 'ham' 'ham' 'ham']\n",
      "True labels: ['ham' 'ham' 'ham' 'ham' 'ham']\n"
     ]
    }
   ],
   "source": [
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "y_pred = log_reg_model.predict(X_test_vectorized)\n",
    "print(f\"Predictions: {y_pred[:5]}\")\n",
    "print(f\"True labels: {y_test[:5].values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f82e2fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.98\n",
      "Confusion Matrix:\n",
      "[[732  17]\n",
      " [  8 278]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.98      0.98       749\n",
      "        spam       0.94      0.97      0.96       286\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.97      0.97      0.97      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy: {test_accuracy:.2f}\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=['ham', 'spam'])\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "class_report = classification_report(y_test, y_pred, target_names=['ham', 'spam'])\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48bc2a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names:\n",
      "['aa' 'aaa' 'aaas' 'aabda' 'aabvmmq' 'aac' 'aaer' 'aafco' 'aaiabe'\n",
      " 'aaigrcrb' 'aaihmqv' 'aalland' 'aambique' 'aamlrg' 'aaoeuro' 'aarhus'\n",
      " 'aaron' 'aashqcsny' 'aavilable' 'aaxrzm']\n",
      "Total number of features: 39999\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"Feature names:\")\n",
    "print(feature_names[:20])\n",
    "print(f\"Total number of features: {len(feature_names)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10fc4204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive features:\n",
      "prices: 0.8814\n",
      "http: 0.8448\n",
      "no: 0.8321\n",
      "hello: 0.7732\n",
      "pain: 0.7499\n",
      "paliourg: 0.7062\n",
      "remove: 0.7043\n",
      "removed: 0.6887\n",
      "here: 0.6746\n",
      "only: 0.6382\n",
      "money: 0.6323\n",
      "more: 0.6306\n",
      "mobile: 0.5919\n",
      "hi: 0.5664\n",
      "laptop: 0.5504\n",
      "vi: 0.5362\n",
      "loading: 0.5340\n",
      "meds: 0.5163\n",
      "software: 0.5160\n",
      "rolex: 0.5125\n",
      "\n",
      "Top negative features:\n",
      "june: -0.7698\n",
      "deals: -0.7850\n",
      "numbers: -0.8223\n",
      "gas: -0.8307\n",
      "wassup: -0.8564\n",
      "know: -0.8870\n",
      "nom: -0.9132\n",
      "sitara: -0.9571\n",
      "revised: -0.9967\n",
      "pictures: -1.0126\n",
      "xls: -1.0805\n",
      "hpl: -1.0860\n",
      "neon: -1.1450\n",
      "meter: -1.1756\n",
      "deal: -1.1818\n",
      "daren: -1.2874\n",
      "doc: -1.3422\n",
      "thanks: -1.3592\n",
      "enron: -1.5275\n",
      "attached: -1.5785\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "coefficients = log_reg_model.coef_[0]\n",
    "\n",
    "feature_importance = dict(zip(feature_names, coefficients))\n",
    "\n",
    "sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top positive features:\")\n",
    "for feature, importance in sorted_features[:20]: \n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "print(\"\\nTop negative features:\")\n",
    "for feature, importance in sorted_features[-20:]:  \n",
    "    print(f\"{feature}: {importance:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20595a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 positive features:\n",
      "        Feature  Coefficient\n",
      "28167    prices     0.881353\n",
      "17554      http     0.844817\n",
      "24839        no     0.832126\n",
      "16806     hello     0.773189\n",
      "26256      pain     0.749867\n",
      "26293  paliourg     0.706160\n",
      "30028    remove     0.704295\n",
      "30029   removed     0.688692\n",
      "16867      here     0.674572\n",
      "25654      only     0.638214\n",
      "\n",
      "Top 10 negative features:\n",
      "        Feature  Coefficient\n",
      "2539   attached    -1.578474\n",
      "12439     enron    -1.527466\n",
      "35224    thanks    -1.359199\n",
      "10878       doc    -1.342169\n",
      "9327      daren    -1.287420\n",
      "9524       deal    -1.181765\n",
      "23111     meter    -1.175568\n",
      "24532      neon    -1.145046\n",
      "17474       hpl    -1.085955\n",
      "39237       xls    -1.080489\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "feature_importance_df['Absolute_Coefficient'] = feature_importance_df['Coefficient'].abs()\n",
    "\n",
    "sorted_features = feature_importance_df.sort_values(by='Absolute_Coefficient', ascending=False)\n",
    "\n",
    "top_positive_features = sorted_features[sorted_features['Coefficient'] > 0].head(10)\n",
    "print(\"Top 10 positive features:\")\n",
    "print(top_positive_features[['Feature', 'Coefficient']])\n",
    "\n",
    "top_negative_features = sorted_features[sorted_features['Coefficient'] < 0].head(10)\n",
    "print(\"\\nTop 10 negative features:\")\n",
    "print(top_negative_features[['Feature', 'Coefficient']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
